{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPClCR2G7wcQN3zRIQ/an+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schwarer2006/ASP.NET-Simple-Login-Application/blob/master/Komplexes_JOB_CV_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Herunterladen des Tokenizers\n",
        "nltk.download('stopwords')  # Herunterladen der Stopwörter"
      ],
      "metadata": {
        "id": "QGw1kI3RnEW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0ac7fb-b788-4571-a387-2fcb1b5bbe95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "ZksSFQgAqcOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from datetime import datetime\n",
        "\n",
        "# NLTK-Ressourcen herunterladen\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Laden und Bereinigen von Textdateien\n",
        "def load_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read().lower()  # Direkt in Kleinbuchstaben konvertieren\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Überflüssige Leerzeichen entfernen\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Sonderzeichen entfernen\n",
        "    return text\n",
        "\n",
        "resume_text = load_text('/content/lebenslauf.txt')\n",
        "job_description_text = load_text('/content/stellenbeschreibung.txt')\n",
        "\n",
        "# Tokenisierung und Entfernung von Stoppwörtern\n",
        "stop_words = set(stopwords.words('german'))\n",
        "def tokenize_and_remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "resume_tokens = tokenize_and_remove_stopwords(resume_text)\n",
        "job_description_tokens = tokenize_and_remove_stopwords(job_description_text)\n",
        "\n",
        "# Cosinus-Ähnlichkeit berechnen\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = CountVectorizer()\n",
        "    vectors = vectorizer.fit_transform([text1, text2]).toarray()\n",
        "    return cosine_similarity(vectors)[0][1]\n",
        "\n",
        "similarity_score = calculate_cosine_similarity(resume_text, job_description_text)\n",
        "\n",
        "# Funktion zur Erstellung und Speicherung von Visualisierungen als PDF\n",
        "def save_visualizations_to_pdf(similarity_score, name, vorname, stellenname):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    pdf_path = f'/content/visualizations_{timestamp}.pdf'\n",
        "    with PdfPages(pdf_path) as pdf:\n",
        "        # Persönliche Informationen und Übereinstimmungsdaten auf einer Seite\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        info_text = (f\"Name: {name}\\nVorname: {vorname}\\nStellenname: {stellenname}\\n\"\n",
        "                     f\"Datum: {datetime.now().strftime('%d.%m.%Y')}\\n\"\n",
        "                     f\"Übereinstimmung in Prozent: {similarity_score * 100:.2f}%\")\n",
        "        ax.text(0.5, 0.5, info_text, fontsize=12, ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.axis('off')\n",
        "        pdf.savefig(fig)\n",
        "        plt.close(fig)\n",
        "\n",
        "        # Visualisierungen für Lebenslauf und Stellenbeschreibung\n",
        "        for text, title in [(resume_text, 'Resume Wordcloud'), (job_description_text, 'Job Description Wordcloud')]:\n",
        "            fig = plt.figure(figsize=(10, 5))\n",
        "            wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "            plt.imshow(wordcloud, interpolation='bilinear')\n",
        "            plt.axis('off')\n",
        "            plt.title(title)\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n",
        "\n",
        "        # Wortfrequenzdiagramme\n",
        "        for tokens, title in [(resume_tokens, 'Resume Word Frequency'), (job_description_tokens, 'Job Description Word Frequency')]:\n",
        "            fig = plt.figure(figsize=(10, 6))\n",
        "            word_freq = Counter(tokens)\n",
        "            df = pd.DataFrame(list(word_freq.items()), columns=['Word', 'Frequency']).sort_values('Frequency', ascending=False)\n",
        "            sns.barplot(x='Frequency', y='Word', data=df.head(20), palette='viridis')\n",
        "            plt.title(title)\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n",
        "\n",
        "    print(f\"PDF gespeichert unter: {pdf_path}\")\n",
        "\n",
        "# Beispieldaten\n",
        "name = \"Schwarz\"\n",
        "vorname = \"Erik\"\n",
        "stellenname = \"SQL Business Intelligence Entwickler\"\n",
        "\n",
        "# Visualisierungen in PDF speichern\n",
        "save_visualizations_to_pdf(similarity_score, name, vorname, stellenname)\n"
      ],
      "metadata": {
        "id": "vpjT5myGdnyQ",
        "outputId": "6b831142-56b4-42d8-c5fd-8153cfb48e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-32-4c4ac825ae0c>:78: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x='Frequency', y='Word', data=df.head(20), palette='viridis')\n",
            "<ipython-input-32-4c4ac825ae0c>:78: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x='Frequency', y='Word', data=df.head(20), palette='viridis')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF gespeichert unter: /content/visualizations_2024-04-19_08-30-27.pdf\n"
          ]
        }
      ]
    }
  ]
}